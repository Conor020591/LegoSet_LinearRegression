{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32d51b2",
   "metadata": {},
   "source": [
    "# Predicting Lego Set Prices\n",
    "As new lego sets approach release, there are rumors and leaks, sometimes containing all of the details of the set.\n",
    "The objective of this model is to be able to predict as accurately as possible, from the available information what hte price of these sets is going to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e79010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from category_encoders import BinaryEncoder\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968716c",
   "metadata": {},
   "source": [
    "Here we import the data generated from the LegoEDA project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a874c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Unnamed: 0 Set_number                       Name Set_type       Theme  \\\n",
       "0            212      702-2            Small Basic Set   Normal   SAMSONITE   \n",
       "1            217      717-1         Junior Constructor   Normal   SAMSONITE   \n",
       "2            218      725-3                  Town Plan   Normal   SAMSONITE   \n",
       "3            279      450-2        Deluxe Building Set   Normal   SAMSONITE   \n",
       "4            281      615-1         Samsonite Gift Set   Normal   SAMSONITE   \n",
       "...          ...        ...                        ...      ...         ...   \n",
       "6787       19108    80043-1       Yellow Tusk Elephant   Normal  MONKIE KID   \n",
       "6788       19109    80044-1  Monkie Kid's Team Hideout   Normal  MONKIE KID   \n",
       "6789       19110    80045-1     Monkey King Ultra Mech   Normal  MONKIE KID   \n",
       "6790       19111    80110-1     Lunar New Year Display   Normal    SEASONAL   \n",
       "6791       19112    80111-1      Lunar New Year Parade   Normal    SEASONAL   \n",
       "\n",
       "           Theme_group                       Subtheme  Year_released  Pieces  \\\n",
       "0              Vintage                      BASIC SET         1961.0   109.0   \n",
       "1              Vintage                      BASIC SET         1961.0   510.0   \n",
       "2              Vintage                      TOWN PLAN         1961.0   711.0   \n",
       "3              Vintage                      BASIC SET         1963.0   450.0   \n",
       "4              Vintage                      BASIC SET         1963.0   615.0   \n",
       "...                ...                            ...            ...     ...   \n",
       "6787  Action/Adventure                       SEASON 4         2023.0   844.0   \n",
       "6788  Action/Adventure                       SEASON 4         2023.0  1582.0   \n",
       "6789  Action/Adventure                       SEASON 4         2023.0  1705.0   \n",
       "6790     Miscellaneous  CHINESE TRADITIONAL FESTIVALS         2023.0   872.0   \n",
       "6791     Miscellaneous  CHINESE TRADITIONAL FESTIVALS         2023.0  1653.0   \n",
       "\n",
       "      Minifigs   Price Age_range  \n",
       "0          0.0    1.95       NaN  \n",
       "1          0.0   16.95       NaN  \n",
       "2          0.0   25.00       NaN  \n",
       "3          0.0   10.95     4 - 9  \n",
       "4          0.0   14.95    5 - 10  \n",
       "...        ...     ...       ...  \n",
       "6787       5.0   79.99        8+  \n",
       "6788       6.0  139.99        9+  \n",
       "6789       6.0  159.99       10+  \n",
       "6790       0.0   89.99        8+  \n",
       "6791      18.0  129.99        8+  \n",
       "\n",
       "[6792 rows x 12 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in clean data\n",
    "lego_mod_df = pd.read_csv('legoData_mod.csv')\n",
    "lego_mod_df.head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1de64",
   "metadata": {},
   "source": [
    "Just a reminder of what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8963d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Set_numbers: 6792\n",
      "Nulls in Set_number: 0\n",
      "Unique Names: 6154\n",
      "Nulls in Name: 0\n",
      "Unique Set_types: 4\n",
      "Nulls in Set_type: 0\n",
      "Unique Themes: 133\n",
      "Nulls in Theme: 0\n",
      "Unique Theme_groups: 14\n",
      "Nulls in Theme_group: 0\n",
      "Unique Subthemes: 541\n",
      "Nulls in Subtheme: 0\n",
      "Unique Age_ranges: 48\n",
      "Nulls in Age_range: 2573\n"
     ]
    }
   ],
   "source": [
    "#Numerical features, without Price, which is our target variable\n",
    "lego_num_cols=['Year_released', 'Pieces', 'Minifigs']\n",
    "#Categorical features\n",
    "lego_cat_cols=['Set_number', 'Name', 'Set_type', 'Theme', 'Theme_group', 'Subtheme', 'Age_range']\n",
    "lego_num = lego_mod_df[lego_num_cols]\n",
    "lego_cat = lego_mod_df[lego_cat_cols]\n",
    "\n",
    "for i in lego_cat.columns:\n",
    "    print(\"Unique \"+ str(i)+ \"s: \"+ str(len(lego_cat[i].unique())))\n",
    "    print(\"Nulls in \"+ str(i)+ \": \"+ str(lego_cat[i].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5244f",
   "metadata": {},
   "source": [
    "## Split to features and target and also make validation set\n",
    "also going to shuffle the dataset and saved the shuffled set for use in other projects for comparisson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1901dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lego_mod_df = lego_mod_df.sample(frac = 1)\n",
    "\n",
    "lego_mod_df.to_csv('legoData_shuffled.csv', sep = ',')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, val_set = train_test_split(lego_mod_df, test_size=0.2, random_state=0)\n",
    "\n",
    "y = train_set.Price\n",
    "X = train_set.drop(['Price'], axis=1)\n",
    "\n",
    "\n",
    "y_val = val_set.Price\n",
    "X_val = val_set.drop(['Price'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b12ce",
   "metadata": {},
   "source": [
    "## Define model function\n",
    "Here I define a function that reads in the preprocessor and the data itself.\n",
    "It then does a cross validation to output the desired scoring parameters.\n",
    "I am going to look at three parameters, the r2, mean squared error (MSE) and mean absolute error (MAE).\n",
    "MSE will be the main gauge of how the model improves. \n",
    "MAE is just included as it is in the same scale as the input data and is more intuitive to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59dabf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(preprocessor,X,y):    \n",
    "\n",
    "\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', LinearRegression(fit_intercept=True))\n",
    "                             ])\n",
    "    \n",
    "    scoring = ['r2','neg_root_mean_squared_error']\n",
    "    scores = cross_validate(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring=scoring,\n",
    "                              return_train_score=True)\n",
    "\n",
    "#    print(\"mean r2: train = \"+str(scores['train_r2'].mean())+\", test = \"+str(scores['test_r2'].mean()))\n",
    "#    print(\"mean RMSE: train = \"+str(-1*scores['train_neg_root_mean_squared_error'].mean())+\", test = \"+str(-1*scores['test_neg_root_mean_squared_error'].mean()))\n",
    "   \n",
    "    return -1*scores['test_neg_root_mean_squared_error'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfe0ef",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Numerical Data\n",
    "I want to scall all of my variables to between 0 and 1, I first do this for only pieces, as this is the most correlated feature with price, to get a baseline of measurements for my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf152b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean r2: train = 0.7354515276743151, test = 0.7270306754334104\n",
      "mean RMSE: train = 28.997860012463327, test = 29.054222564992152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.997860012463327"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, ['Pieces',]),\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb25f2",
   "metadata": {},
   "source": [
    "Next I add in minifigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd2eec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean r2: train = 0.7489002947653879, test = 0.7399200301133515\n",
      "mean RMSE: train = 28.250894400119506, test = 28.342126602583573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.250894400119506"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, ['Pieces','Minifigs']),\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "linear_model(preprocessor,X,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0002aa0",
   "metadata": {},
   "source": [
    "We can see the MSE and MAE drop significantly, as well as a slight increase in r2\n",
    "\n",
    "the next step is to add in release year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f435465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean r2: train = 0.7493007577188824, test = 0.7403554660013063\n",
      "mean RMSE: train = 28.228475952466475, test = 28.321059959505135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.228475952466475"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, ['Pieces','Minifigs','Year_released']),\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391160fc",
   "metadata": {},
   "source": [
    "Adding polynomials to see if they improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "34b573e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.968616471809487"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "polyn = preprocessing.PolynomialFeatures(2) \n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scale', scaler),\n",
    "    ('poly', polyn)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, ['Pieces','Minifigs','Year_released']),\n",
    "        \n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58643c09",
   "metadata": {},
   "source": [
    "We can see that adding 2nd order polynomials decreases MAE and MSE on the test data, however going beyond this causes overfitting.\n",
    "I am going to graph the RMSE of the data vs cutout year below. (I exclude the last ten years as this would remove too much data from the pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d4fc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961\n",
      "mean r2: train = 0.7775510789161808, test = 0.7777037282586322\n",
      "mean RMSE: train = 26.697069325745968, test = 26.49463030629597\n",
      "1962\n",
      "mean r2: train = 0.7775361652775343, test = 0.7776639862655507\n",
      "mean RMSE: train = 26.702439352300132, test = 26.501253636869063\n",
      "1963\n",
      "mean r2: train = 0.7775361652775343, test = 0.7776639862655507\n",
      "mean RMSE: train = 26.702439352300132, test = 26.501253636869063\n",
      "1964\n",
      "mean r2: train = 0.7777279095131789, test = 0.778293950509042\n",
      "mean RMSE: train = 26.69367020070893, test = 26.463282928278232\n",
      "1965\n",
      "mean r2: train = 0.7776414441226972, test = 0.7782187544302226\n",
      "mean RMSE: train = 26.706150042796317, test = 26.474509685216606\n",
      "1966\n",
      "mean r2: train = 0.7776248012072134, test = 0.7782039071358786\n",
      "mean RMSE: train = 26.709785516708724, test = 26.47826573396002\n",
      "1967\n",
      "mean r2: train = 0.7775471908500107, test = 0.7780883352281807\n",
      "mean RMSE: train = 26.730274271969243, test = 26.500569194209742\n",
      "1968\n",
      "mean r2: train = 0.777443305648735, test = 0.7779874382754294\n",
      "mean RMSE: train = 26.751684164042558, test = 26.520324120467244\n",
      "1969\n",
      "mean r2: train = 0.777414596857066, test = 0.777934169855935\n",
      "mean RMSE: train = 26.762869191504308, test = 26.53345849345821\n",
      "1970\n",
      "mean r2: train = 0.7774280254892659, test = 0.7778925736831789\n",
      "mean RMSE: train = 26.770331858467365, test = 26.544396117178785\n",
      "1971\n",
      "mean r2: train = 0.7773968272694217, test = 0.7778817425176332\n",
      "mean RMSE: train = 26.776114489535484, test = 26.54805477726536\n",
      "1972\n",
      "mean r2: train = 0.7776199047971228, test = 0.7780701918343282\n",
      "mean RMSE: train = 26.78080229773455, test = 26.554431950547144\n",
      "1973\n",
      "mean r2: train = 0.7776075969459577, test = 0.7780589679550171\n",
      "mean RMSE: train = 26.782726276268573, test = 26.555971789118864\n",
      "1974\n",
      "mean r2: train = 0.7777066428622138, test = 0.7781912575926524\n",
      "mean RMSE: train = 26.781400895331792, test = 26.552543672297872\n",
      "1975\n",
      "mean r2: train = 0.7776851157176969, test = 0.7781724349153428\n",
      "mean RMSE: train = 26.786836524631912, test = 26.557806716237177\n",
      "1976\n",
      "mean r2: train = 0.7776829860903596, test = 0.7781672990632388\n",
      "mean RMSE: train = 26.78856053307097, test = 26.559899174886215\n",
      "1977\n",
      "mean r2: train = 0.7777645575079738, test = 0.778267726237479\n",
      "mean RMSE: train = 26.79348942885382, test = 26.564831521281626\n",
      "1978\n",
      "mean r2: train = 0.7777667522164107, test = 0.7782680271539566\n",
      "mean RMSE: train = 26.796821888449198, test = 26.56757184120263\n",
      "1979\n",
      "mean r2: train = 0.7777078560730641, test = 0.7781813080277002\n",
      "mean RMSE: train = 26.81156387293915, test = 26.58401284670625\n",
      "1980\n",
      "mean r2: train = 0.7777058828899287, test = 0.7781822277976186\n",
      "mean RMSE: train = 26.816391283767977, test = 26.588531557693027\n",
      "1981\n",
      "mean r2: train = 0.7776706315590587, test = 0.7772843424673743\n",
      "mean RMSE: train = 26.855181185060758, test = 26.650245457152845\n",
      "1982\n",
      "mean r2: train = 0.7778102223760045, test = 0.7782497377426116\n",
      "mean RMSE: train = 26.872795695062212, test = 26.64512540718515\n",
      "1983\n",
      "mean r2: train = 0.7779099847266622, test = 0.778310560381432\n",
      "mean RMSE: train = 26.87370558955961, test = 26.648540922465607\n",
      "1984\n",
      "mean r2: train = 0.7779187317049698, test = 0.7783204355519183\n",
      "mean RMSE: train = 26.877956778644705, test = 26.651687120212166\n",
      "1985\n",
      "mean r2: train = 0.778046786671141, test = 0.7784054943949477\n",
      "mean RMSE: train = 26.89385610030602, test = 26.670660138860946\n",
      "1986\n",
      "mean r2: train = 0.7779650314900891, test = 0.7783211470725695\n",
      "mean RMSE: train = 26.931205785718202, test = 26.707759097732936\n",
      "1987\n",
      "mean r2: train = 0.779046898169, test = 0.7794238904211678\n",
      "mean RMSE: train = 26.8951206166086, test = 26.67047114017464\n",
      "1988\n",
      "mean r2: train = 0.7788388358151618, test = 0.7790995155968011\n",
      "mean RMSE: train = 26.95905774902139, test = 26.738310462876946\n",
      "1989\n",
      "mean r2: train = 0.7788584268152856, test = 0.7791128132226293\n",
      "mean RMSE: train = 26.980677681981582, test = 26.759330132512524\n",
      "1990\n",
      "mean r2: train = 0.7783156837256233, test = 0.7788717327310695\n",
      "mean RMSE: train = 27.06449127421356, test = 26.80445150766056\n",
      "1991\n",
      "mean r2: train = 0.7782090197661888, test = 0.7778172871152276\n",
      "mean RMSE: train = 27.109352262912928, test = 26.878758018933176\n",
      "1992\n",
      "mean r2: train = 0.7782554838462518, test = 0.7770051378913023\n",
      "mean RMSE: train = 27.162569002838744, test = 26.990024061206118\n",
      "1993\n",
      "mean r2: train = 0.7781191563232948, test = 0.77665061544051\n",
      "mean RMSE: train = 27.237084588910033, test = 27.070718222346926\n",
      "1994\n",
      "mean r2: train = 0.7777269979893824, test = 0.777235118494998\n",
      "mean RMSE: train = 27.35748544583517, test = 27.12536032345871\n",
      "1995\n",
      "mean r2: train = 0.7778096606488158, test = 0.7772848942913473\n",
      "mean RMSE: train = 27.410350284736545, test = 27.17755091426705\n",
      "1996\n",
      "mean r2: train = 0.7783413127222698, test = 0.7767797703101011\n",
      "mean RMSE: train = 27.48221043811692, test = 27.316249374641888\n",
      "1997\n",
      "mean r2: train = 0.7778302058477073, test = 0.776046951605551\n",
      "mean RMSE: train = 27.658079293406992, test = 27.492819164541118\n",
      "1998\n",
      "mean r2: train = 0.7774975692697303, test = 0.7754973844334889\n",
      "mean RMSE: train = 27.84966030656745, test = 27.693536823935666\n",
      "1999\n",
      "mean r2: train = 0.7814100594419859, test = 0.7797558329266323\n",
      "mean RMSE: train = 27.813190005355345, test = 27.598820148603625\n",
      "2000\n",
      "mean r2: train = 0.7828811296288916, test = 0.781589327318909\n",
      "mean RMSE: train = 27.887264703847013, test = 27.641228043666388\n",
      "2001\n",
      "mean r2: train = 0.7843881778417311, test = 0.7822035655930274\n",
      "mean RMSE: train = 27.958788763559845, test = 27.75974140919835\n",
      "2002\n",
      "mean r2: train = 0.7848072338640834, test = 0.7828359174225595\n",
      "mean RMSE: train = 28.120099601335426, test = 27.90739910897929\n",
      "2003\n",
      "mean r2: train = 0.7881756213121616, test = 0.7870855020224642\n",
      "mean RMSE: train = 28.11005507613665, test = 27.83697323170087\n",
      "2004\n",
      "mean r2: train = 0.7902969232662791, test = 0.7867740457642624\n",
      "mean RMSE: train = 28.222407129234348, test = 28.102561048329914\n",
      "2005\n",
      "mean r2: train = 0.7954296362622175, test = 0.7896501899930941\n",
      "mean RMSE: train = 28.09844799085987, test = 28.1090649928277\n",
      "2006\n",
      "mean r2: train = 0.796633323497567, test = 0.7927684170160564\n",
      "mean RMSE: train = 28.215889493389106, test = 28.053449147930287\n",
      "2007\n",
      "mean r2: train = 0.8012362755878808, test = 0.7958492095521668\n",
      "mean RMSE: train = 28.108826659195323, test = 28.054970748300132\n",
      "2008\n",
      "mean r2: train = 0.8014268997904604, test = 0.7974858633266331\n",
      "mean RMSE: train = 28.16739225980509, test = 28.064086721602262\n",
      "2009\n",
      "mean r2: train = 0.8030856801045949, test = 0.7948867164484517\n",
      "mean RMSE: train = 28.235037631777082, test = 28.421870871079044\n",
      "2010\n",
      "mean r2: train = 0.8069915617033725, test = 0.799112519046186\n",
      "mean RMSE: train = 28.228222744836494, test = 28.456679609653882\n",
      "2011\n",
      "mean r2: train = 0.8053711567604331, test = 0.7950636411428718\n",
      "mean RMSE: train = 28.541363075243574, test = 28.95284774614263\n",
      "2012\n",
      "mean r2: train = 0.8026078220396821, test = 0.7919938893421175\n",
      "mean RMSE: train = 29.112416547756652, test = 29.5293264194817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f29a29b52d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year_list = []\n",
    "MSE_list = []\n",
    "for year in range(int(lego_mod_df.Year_released.min()),int(lego_mod_df.Year_released.max())-10):\n",
    "    lego_mod_postdate_df = lego_mod_df[lego_mod_df.Year_released >= year]\n",
    "    y_new = lego_mod_postdate_df.Price\n",
    "    X_new = lego_mod_postdate_df.drop(['Price'], axis=1)\n",
    "\n",
    "\n",
    "    scaler  = preprocessing.StandardScaler()\n",
    "    polyn = preprocessing.PolynomialFeatures(2) \n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scale', scaler),\n",
    "        ('poly', polyn)\n",
    "    ])\n",
    "    print(year)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numerical_transformer, ['Pieces','Minifigs','Year_released']),\n",
    "\n",
    "        ],\n",
    "    remainder = 'drop'\n",
    "    )\n",
    "\n",
    "    year_list.append(year)\n",
    "    MSE_list.append(linear_model(preprocessor,X_new,y_new))\n",
    "plt.plot(year_list, MSE_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d557b9",
   "metadata": {},
   "source": [
    "We see that the more data the more accurate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "308abbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.968616471809487"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last time I'll define the numerical transformer, for now.\n",
    "scaler  = preprocessing.StandardScaler()\n",
    "polyn = preprocessing.PolynomialFeatures(2) \n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scale', scaler),\n",
    "    ('poly', polyn)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, ['Pieces','Minifigs','Year_released'])\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6020073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.968616471809487"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last time I'll define the numerical transformer, for now.\n",
    "scaler  = preprocessing.StandardScaler()\n",
    "polyn = preprocessing.PolynomialFeatures(2) \n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scale', scaler),\n",
    "    ('poly', polyn)\n",
    "])\n",
    "\n",
    "full_numerical_transformer = ('num', numerical_transformer, ['Pieces','Minifigs','Year_released'])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[full_numerical_transformer\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35295974",
   "metadata": {},
   "source": [
    "#### Categorical Data\n",
    "Next we will look at the categorical data.\n",
    "\n",
    "Some of these features have many unique variables, whereas some have few, as such I will test to see which are better candidates for onehot, binary and target encoding. Below is a function which tests a given feature's test RMSE and outputs which type of encoding lowers the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d6439d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "def cat_tester(feat,full_numerical_transformer,  X, y):\n",
    "    BI_categorical_transformer = Pipeline(steps=[\n",
    "        ('Binary', BinaryEncoder(return_df=True))\n",
    "\n",
    "    ])\n",
    "    OH_categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'first'))\n",
    "\n",
    "    ])\n",
    "\n",
    "    TAR_categorical_transformer = Pipeline(steps=[\n",
    "        ('Target', TargetEncoder())\n",
    "\n",
    "    ])\n",
    "    Encoder_Array = [OH_categorical_transformer, BI_categorical_transformer, TAR_categorical_transformer]\n",
    "    Encoder_names = [\"OneHot\",\"Binary\", \"Target\",]\n",
    "    lowest =0\n",
    "    lowest_name =''\n",
    "    for i, (encoder,encoderName) in enumerate(zip(Encoder_Array,Encoder_names)):\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                        full_numerical_transformer,\n",
    "                      ('test_cat', encoder, [feat]),\n",
    "\n",
    "            ],\n",
    "            remainder = 'drop'\n",
    "    )\n",
    "\n",
    "        rmse_score = linear_model(preprocessor,X,y)\n",
    "        if i==0:\n",
    "            lowest_name =encoderName\n",
    "            lowest = rmse_score\n",
    "        elif lowest > rmse_score:\n",
    "            lowest_name =encoderName\n",
    "            lowest = rmse_score\n",
    "#        print(encoderName+\": \"+ str(rmse_score))\n",
    "    return lowest_name, lowest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e653aeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set_type: Target = 27.967237473854993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: OneHot = 23.396881822698045\n",
      "Theme_group: OneHot = 25.030535205849837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtheme: Target = 27.425683648526313\n"
     ]
    }
   ],
   "source": [
    "cat_feats = [ 'Set_type', 'Theme', 'Theme_group', 'Subtheme']\n",
    "for feat in cat_feats:\n",
    "    encoder  = cat_tester(feat,full_numerical_transformer,X,y)\n",
    "    print(feat + ': ' +encoder[0] + ' = ' + str(encoder[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900797bd",
   "metadata": {},
   "source": [
    "The RMSE for no categorical data was  27.968616471809487\n",
    "The values that just include the the numerical data and a given categorical feature, for the \"best\" encoding types are given as:\n",
    "\n",
    "Set_type: Target = 27.967237473854993\n",
    "Theme: OneHot = 23.396881822698045\n",
    "Theme_group: OneHot = 25.030535205849837\n",
    "Subtheme: Target = 27.425683648526313\n",
    "\n",
    "This shows that including each of these improves on the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6064a8a",
   "metadata": {},
   "source": [
    "The below run specifies our new best model (this actually excludes subtheme from the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d8a40fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:182: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.15407273148164"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Run\n",
    "OH_categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'first'))\n",
    "    \n",
    "])\n",
    "\n",
    "TAR_categorical_transformer = Pipeline(steps=[\n",
    "    ('Target', ce.TargetEncoder())\n",
    "    \n",
    "])\n",
    "BI_categorical_transformer = Pipeline(steps=[\n",
    "    ('Binary', BinaryEncoder(return_df=True))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, ['Pieces','Minifigs','Year_released']),\n",
    "       #           ('BI_cat', BI_categorical_transformer, ['Set_type']),\n",
    "                  ('TAR_cat', TAR_categorical_transformer, ['Subtheme','Set_type']),\n",
    "                  ('OH_cat', OH_categorical_transformer, ['Theme_group', 'Theme'])\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289e5ca",
   "metadata": {},
   "source": [
    "Now let's run a prediction on the validation set, training on the full trianing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a54884ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.049360526801557"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', LinearRegression(fit_intercept=True))\n",
    "                             ])\n",
    "my_pipeline.fit(X, y)\n",
    "y_preds = my_pipeline.predict(X_val)\n",
    "np.sqrt(mean_squared_error(y_val, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acac238",
   "metadata": {},
   "source": [
    "Not a bad result, my nex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
